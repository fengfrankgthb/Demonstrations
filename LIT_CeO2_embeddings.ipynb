{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fengfrankgthb/Demonstrations/blob/main/LIT_CeO2_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2c6PyqQaNiA"
      },
      "source": [
        "# Showing text embeddings 2025.05.18\n",
        "\n",
        "## 1. Install Necessary Libraries\n",
        "* **sentence-transformers** This is the text embedding library\n",
        "* **scikit-learn** This is the machine learning library\n",
        "* **matplotlib** This is the mat-lab style plotting library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers scikit-learn matplotlib"
      ],
      "metadata": {
        "id": "158mSJto-mYD",
        "outputId": "38613b48-9fde-483c-bbf8-584545d5c7ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. import necessary modules from the libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "jd2Yqvua_ktp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mpl_toolkits.mplot3d**: matplot 3D plotting lib\n",
        "\n",
        "**numpy**: Numerical Python, the fundamental python lib\n",
        "\n",
        "**Axes3D** 3D plotting class\n",
        "\n",
        "**PCA** Principal Components Analysis for linear dimension reduction.\n",
        "\n",
        "**TSNE** t-SNE non-linear dimension reduction to creat more scattered effect"
      ],
      "metadata": {
        "id": "XPORFA-auaqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "# set matplot to inline (static) mode, or notebook for interactive mode)\n",
        "# even though default is inline mode, be explicit to avoid any confusion\n",
        "# the interactive notebook mode is often unstable at colab environment\n",
        "# alternative is set as 'inline' and use 'plotly'.\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "d8ArIZFq_uxp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Imput text data (CeO2 Sample)\n",
        "\n",
        "Used *118HHH Q1 on CeO2-NPs* for illustration, breaking into 9 components:\n",
        "\n",
        "* Pa = All Sentences combined in Prompt\n",
        "* P1 = 1st sentence in Prompt\n",
        "* P2 = 2nd sentence in Prompt\n",
        "* P3 = 3rd sentence in Prompt\n",
        "* Q? = the Question sentence\n",
        "* Ax = wrong choice A\n",
        "* Bv = correct answer B\n",
        "* Cx = wrong choice C\n",
        "* Dx = wrong choice D"
      ],
      "metadata": {
        "id": "6NTtMzbl_5f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: CeO2 Question\n",
        "# This is a hard question used to directly compare with 5Vs in section 8.1 and 8.2\n",
        "sentences = [\"Pa: Some fuel additives contain cerium oxide nanoparticles (CeO2-NPs), which can leach into waterways and soils via waste water. In a 2015 study Mael Garaud and colleagues found that CeO2-NPs can accumulate in the bodies of zebra mussels (Dreissena polymorpha). While bioaccumulation of manufactured nanoparticles may be inherently worrisome, it has been hypothesized that CeO2-NPs bioaccumulation in invertebrate like D. polymorpha could serve a valuable proxy role, observing the need for manufacturers to conduct costly and intrusive sampling of vertebrate species--such as rainbow trout (Oncorhynchus mykiss), commonly used in regulatory compliance testing--for manipulative bioaccumulation, as environmental protection laws currently require.\",\n",
        "    \"P1: Some fuel additives contain cerium oxide nanoparticles (CeO2-NPs), which can leach into waterways and soils via waste water.\",\n",
        "    \"P2: In a 2015 study Mael Garaud and colleagues found that CeO2-NPs can accumulate in the bodies of zebra mussels (Dreissena polymorpha).\",\n",
        "    \"P3: While bioaccumulation of manufactured nanoparticles may be inherently worrisome, it has been hypothesized that CeO2-NPs bioaccumulation in invertebrate like D. polymorpha could serve a valuable proxy role, observing the need for manufacturers to conduct costly and intrusive sampling of vertebrate species--such as rainbow trout (Oncorhynchus mykiss), commonly used in regulatory compliance testing--for manipulative bioaccumulation, as environmental protection laws currently require.\",\n",
        "    \"Q?: Which finding, if true, would most directly weaken the hypothesis presented in the text?\",\n",
        "    \"Ax) When D. polymorpha and O. mykiss are exposed to similar levels of CeO2-NPs, concentrations of CeO2-NPs in animals of both species show little variation from individual to individual.\",\n",
        "    \"Bv) The rate of CeO2-NPs uptake in D. polymorpha differs from the rate of CeO2-NPs uptake in O. mykiss in a way that is not yet well understood by researchers.\",\n",
        "    \"Cx) D.polymorpha has been shown to accumulate several other types of manufactured nanoparticles in addition to CeO2-NPs, whereas O. mykiss has been shown to accumulate only CeO2-NPs.\",\n",
        "    \"Dx) Compared with O. mykiss, D.polymorpha can accumulate detectable CeO2-NPs concentrations with significantly fewer negative effects.\"\n",
        "]"
      ],
      "metadata": {
        "id": "xFnLqNPQ_-54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Queen Egypt\n",
        "# This is medium hard question used to discover abreviation bias among choices\n",
        "sentences = [\"Pa: Archaeologist Christiana Kohler and her team excavated the Egyptian tomb of Queen Merneith, the wife of a First Dynasty pharaoh. Some scholars claim that she also ruled Egypt on her own and was actually the first female pharaoh. The team found a tablet in Merneith’s tomb with writing suggesting that she was in charge of the country’s treasury and other central offices. Whether Merneith was a pharaoh or not, this discovery supports the idea that Merneith likely _______\",\n",
        "    \"P1: Archaeologist Christiana Kohler and her team excavated the Egyptian tomb of Queen Merneith, the wife of a First Dynasty pharaoh.\",\n",
        "    \"P2: Some scholars claim that she also ruled Egypt on her own and was actually the first female pharaoh.\",\n",
        "    \"P3: The team found a tablet in Merneith’s tomb with writing suggesting that she was in charge of the country’s treasury and other central offices.\",\n",
        "    \"Q?: Whether Merneith was a pharaoh or not, this discovery supports the idea that Merneith likely _______ (choose from Av, Bx, Cx, and Dx). \",\n",
        "    \"Av) had an important role in Egypt’s government.\",\n",
        "    \"Bx) lived after rather than before the First Dynasty of Egypt.\",\n",
        "    \"Cx) traveled beyond Egypt’s borders often.\",\n",
        "    \"Dx) created a new form of writing in Egypt.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "X9rF5XJaasNx"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative Example 2: Queen Egypt amended\n",
        "# This is the revised the example 2 to disclose abreviation bias among choices.\n",
        "sentences = [\"Pa: Archaeologist Christiana Kohler and her team excavated the Egyptian tomb of Queen Merneith, the wife of a First Dynasty pharaoh. Some scholars claim that she also ruled Egypt on her own and was actually the first female pharaoh. The team found a tablet in Merneith’s tomb with writing suggesting that she was in charge of the country’s treasury and other central offices. Whether Merneith was a pharaoh or not, this discovery supports the idea that Merneith likely _______\",\n",
        "    \"P1: Archaeologist Christiana Kohler and her team excavated the Egyptian tomb of Queen Merneith, the wife of a First Dynasty pharaoh.\",\n",
        "    \"P2: Some scholars claim that she also ruled Egypt on her own and was actually the first female pharaoh.\",\n",
        "    \"P3: The team found a tablet in Merneith’s tomb with writing suggesting that she was in charge of the country’s treasury and other central offices.\",\n",
        "    \"Q?: This discovery supports that _______ (choose from Av, Bx, Cx, and Dx)?\",\n",
        "    \"Av) Merneith likely had a role in her government\",\n",
        "    \"Bx) Merneith likely lived after the First Dynasty\",\n",
        "    \"Cx) Merneith likely traveld beyond Egypt borders\",\n",
        "    \"Dx) Merneith likely created an Egptian writing.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "T5uZUh9kj0jK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: LNH Study\n",
        "# This is a hard question used to discover multi-relation confusions in text.\n",
        "sentences = [\"Pa: The linguistic niche hypothesis (LNH) posits that the exotericity of languages (how prevalent non-native speakers are) and grammatical complexity are inversely related, which the LNH ascribes to attrition of complex grammatical rules as more non-native speakers adopt the language but fail to acquire those rules. Focusing on two characteristics that are positive indices of grammatical complexity, fusion (when new phonemes arise from the merger of previously distinct ones) and informativity (languages’ capacity for meaningful variation), Olena Shcherbakova and colleagues conducted a quantitative analysis for more than 1,300 languages and claim the outcome is inconsistent with the LNH.\",\n",
        "    \"P1: The linguistic niche hypothesis (LNH) posits that the exotericity of languages (how prevalent non-native speakers are) and grammatical complexity are inversely related, which the LNH ascribes to attrition of complex grammatical rules as more non-native speakers adopt the language but fail to acquire those rules.\",\n",
        "    \"P2: Focusing on two characteristics that are positive indices of grammatical complexity, fusion (when new phonemes arise from the merger of previously distinct ones) and informativity (languages’ capacity for meaningful variation), Olena Shcherbakova and colleagues conducted a quantitative analysis for more than 1,300 languages and claim the outcome is inconsistent with the LNH.\",\n",
        "    \"Pa: The linguistic niche hypothesis (LNH) posits that the exotericity of languages (how prevalent non-native speakers are) and grammatical complexity are inversely related, which the LNH ascribes to attrition of complex grammatical rules as more non-native speakers adopt the language but fail to acquire those rules. Focusing on two characteristics that are positive indices of grammatical complexity, fusion (when new phonemes arise from the merger of previously distinct ones) and informativity (languages’ capacity for meaningful variation), Olena Shcherbakova and colleagues conducted a quantitative analysis for more than 1,300 languages and claim the outcome is inconsistent with the LNH.\",\n",
        "    \"Q?: Which finding, if true, would most directly support Shcherbakova and colleagues’ claim?\",\n",
        "    \"Ax) Shcherbakova and colleagues’ analysis showed a slightly negative correlation between grammatical complexity and fusion and between grammatical complexity and informativity\",\n",
        "    \"Bx) Shcherbakova and colleagues’ analysis showed a slightly negative correlation between grammatical complexity and exotericity.\",\n",
        "    \"Cx) Shcherbakova and colleagues’ analysis showed a slightly positive correlation between grammatical complexity and fusion.\",\n",
        "    \"Dv) Shcherbakova and colleagues’ analysis showed a slightly positive correlation between fusion and exotericity and between informativity and exotericity.\"\n",
        "]"
      ],
      "metadata": {
        "id": "Uv8etHnIkoGz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative Example 3: LNH Study\n",
        "# This is the revised Example 3 to disclose multi-relation confusions in text.\n",
        "sentences = [\"Pa: The linguistic niche hypothesis (LNH) posits that the exotericity of languages (how prevalent non-native speakers are) and grammatical complexity are inversely related, which the LNH ascribes to attrition of complex grammatical rules as more non-native speakers adopt the language but fail to acquire those rules. Focusing on two characteristics that are positive indices of grammatical complexity, fusion (when new phonemes arise from the merger of previously distinct ones) and informativity (languages’ capacity for meaningful variation), Olena Shcherbakova and colleagues conducted a quantitative analysis for more than 1,300 languages and claim the outcome is inconsistent with the LNH.\",\n",
        "    \"P1: The linguistic niche hypothesis (LNH) posits that the exotericity of languages (how prevalent non-native speakers are) and grammatical complexity are inversely related, which the LNH ascribes to attrition of complex grammatical rules as more non-native speakers adopt the language but fail to acquire those rules.\",\n",
        "    \"P2: Focusing on two characteristics that are positive indices of grammatical complexity, fusion (when new phonemes arise from the merger of previously distinct ones) and informativity (languages’ capacity for meaningful variation), Olena Shcherbakova and colleagues conducted a quantitative analysis for more than 1,300 languages and claim the outcome is inconsistent with the LNH.\",\n",
        "    \"Pa: The linguistic niche hypothesis (LNH) posits that the exotericity of languages (how prevalent non-native speakers are) and grammatical complexity are inversely related, which the LNH ascribes to attrition of complex grammatical rules as more non-native speakers adopt the language but fail to acquire those rules. Focusing on two characteristics that are positive indices of grammatical complexity, fusion (when new phonemes arise from the merger of previously distinct ones) and informativity (languages’ capacity for meaningful variation), Olena Shcherbakova and colleagues conducted a quantitative analysis for more than 1,300 languages and claim the outcome is inconsistent with the LNH.\",\n",
        "    \"Q?: Which finding, if true, would most directly support Shcherbakova and colleagues’ claim?\",\n",
        "    \"Ax) Shcherbakova and colleagues’ analysis showed a slightly negative correlation between grammatical complexity and fusion\",\n",
        "    \"Bx) Shcherbakova and colleagues’ analysis showed a slightly negative correlation between grammatical complexity and exotericity.\",\n",
        "    \"Cx) Shcherbakova and colleagues’ analysis showed a slightly positive correlation between grammatical complexity and fusion.\",\n",
        "    \"Dv) Shcherbakova and colleagues’ analysis showed a slightly positive correlation between grammatical complexity and exotericity.\"\n",
        "]"
      ],
      "metadata": {
        "id": "vfZEp-mVA-O_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Generate Embeddings for CeO2 Sample Sentences.\n",
        "\n",
        "Used a pre-trained Sentence Transformer model, `all-mpnet-base-v2`, to generate embeddings for each sentence. This model is a good general-purpose choice, with mapping of sentences & paragraphs to a **768** dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
        "\n",
        "`all-mpnet-base-v2`: is a sentence transformer model that converts sentences and paragraphs into numerical vectors. These vectors, called embeddings, capture the semantic meaning of the text.\n",
        "\n",
        "**Key Features and What it's Used For**:\n",
        "* Sentence Embeddings: The model takes a sentence (or short paragraph) as input and produces a dense vector representation.\n",
        "* 768 Dimensions: is a common dimensionality for these types of models.\n",
        "* MPNet Architecture: is a model that combines the strengths of BERT and XLNet to better understand word order and context.\n",
        "* General Purpose: `all-mpnet-base-v2` is designed to be a general-purpose model, meaning it performs well on a variety of tasks.\n",
        "\n",
        "**Common Applications**:\n",
        "* Semantic Search: Finding sentences or documents with similar meanings.\n",
        "* Information Retrieval: Pulling up relevant information based on a text query.\n",
        "* Clustering: Grouping sentences or paragraphs with similar meanings.\n",
        "* Sentence Similarity: Measuring how alike two pieces of text are.\n",
        "\n",
        "**How to Use It** (in Python with Sentence Transformers):\n",
        "\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    model = SentenceTransformer('all-mpnet-base-v2')\n",
        "        sentences = [\n",
        "        \"This is a simple example.\",\n",
        "        \"Here is another sentence.\",\n",
        "        \"A third sentence for demonstration.\"\n",
        "    ]\n",
        "    embeddings = model.encode(sentences)\n",
        "    print(embeddings)  # Output: A list of 768-dimensional vectors\n",
        "\n",
        "**Why is it Popular?**\n",
        "* Inclusive dataset: a massive dataset of over 1 billion sentence pairs from\n",
        "Natural Language Inference (NLI) datasets, Paraphrase datasets, and a large collection of other published English data from various sources.\n",
        "* Good Performance: It generally ranks high in accuracy for many semantic text understanding tasks.\n",
        "* Efficiency: While very effective, it's also relatively efficient to use.\n",
        "* Ease of Use: Libraries like Sentence Transformers make it very easy to download and use."
      ],
      "metadata": {
        "id": "mFQ_kUZAA5RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model\n",
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "# Generate the embeddings\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "print(\"Shape of embeddings:\", embeddings.shape)\n",
        "print(\"Example embedding (first sentence):\\n\", embeddings[8][:20]) # Print the first 20 dimensions only"
      ],
      "metadata": {
        "id": "O_TbU_wZBkSR",
        "outputId": "01cdf295-5492-4cd8-e1c8-560902a9f132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embeddings: (9, 768)\n",
            "Example embedding (first sentence):\n",
            " [ 0.06450042 -0.00273363 -0.0461126   0.01771595 -0.01685385  0.01462065\n",
            " -0.03381128  0.02044354 -0.0394785   0.0075486   0.03343965 -0.0119477\n",
            "  0.01802935  0.01699202  0.04172963 -0.02462099  0.02869232 -0.02630621\n",
            " -0.01328317  0.00738005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Reduce Dimensionality: 2D with PCA\n",
        "\n",
        "**PCA** = principal component analysis.\n",
        "\n",
        "Principal Components are composite dimensions from the existing 768-dimention embedding dataset. It helps to reduce dimensions while maintaning the most variances mathematically, thus being able to discern the most of datapoints. The ability to discern things is simply the intelligence, or smartness."
      ],
      "metadata": {
        "id": "ocb8gsESB1VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce to 2 dimensions using PCA\n",
        "pca_2d = PCA(n_components=2)\n",
        "reduced_embeddings_2d = pca_2d.fit_transform(embeddings)\n",
        "\n",
        "# Visualize the 2D embeddings\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.scatter(reduced_embeddings_2d[:, 0], reduced_embeddings_2d[:, 1])\n",
        "\n",
        "# Annotate each point with the corresponding sentence\n",
        "for i, txt in enumerate(sentences):\n",
        "    plt.annotate(txt[:2], (reduced_embeddings_2d[i, 0], reduced_embeddings_2d[i, 1]))\n",
        "\n",
        "plt.title(\"2D Visualization of Sentence Embeddings (PCA)\")\n",
        "plt.xlabel(\"PC 1\")\n",
        "plt.ylabel(\"PC 2\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fJeP42tQCDmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Reduce Dimensionality: 3D with PCA\n",
        "\n",
        "### 6.1 3D PCA static"
      ],
      "metadata": {
        "id": "uc8WbutRCRBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce to 3 dimensions using PCA\n",
        "pca_3d = PCA(n_components=3)\n",
        "reduced_embeddings_3d = pca_3d.fit_transform(embeddings)\n",
        "\n",
        "# Visualize the 3D embeddings\n",
        "fig_3d = plt.figure(figsize=(8, 6))\n",
        "ax_3d = fig_3d.add_subplot(111, projection='3d')\n",
        "scatter_3d = ax_3d.scatter(reduced_embeddings_3d[:, 0], reduced_embeddings_3d[:, 1], reduced_embeddings_3d[:, 2])\n",
        "\n",
        "# Annotate each point with the corresponding sentence\n",
        "for i, txt in enumerate(sentences):\n",
        "    ax_3d.text(reduced_embeddings_3d[i, 0], reduced_embeddings_3d[i, 1], reduced_embeddings_3d[i, 2], txt[:2])\n",
        "\n",
        "ax_3d.set_xlabel(\"PC 1\")\n",
        "ax_3d.set_ylabel(\"PC 2\")\n",
        "ax_3d.set_zlabel(\"PC 3\")\n",
        "ax_3d.set_title(\"3D Visualization of Sentence Embeddings (PCA)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fySiUjFOCa9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 3D PCA rotational with P-tet\n",
        "\n",
        "Question domain is illustrated in P-tet. Choices relation to Prompt-Question is shown by the distance from Choice to P-tet."
      ],
      "metadata": {
        "id": "dnOCVriiwN5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "labels = [s[:2] for s in sentences]  # Get first two letters.\n",
        "\n",
        "# Perform PCA to reduce to 3 dimensions\n",
        "pca_3d = PCA(n_components=3)\n",
        "reduced_embeddings_3d = pca_3d.fit_transform(embeddings)\n",
        "\n",
        "# Directly define the indices, assuming P1, P2, P3, Q? are at indices 1, 2, 3, and 4\n",
        "p1_index = 1\n",
        "p2_index = 2\n",
        "p3_index = 3\n",
        "q_index = 4\n",
        "\n",
        "# Extract the 3D coordinates of P1, P2, P3, and Q?\n",
        "p1_coords = reduced_embeddings_3d[p1_index]\n",
        "p2_coords = reduced_embeddings_3d[p2_index]\n",
        "p3_coords = reduced_embeddings_3d[p3_index]\n",
        "q_coords = reduced_embeddings_3d[q_index]\n",
        "\n",
        "# Define the vertices of the tetrahedron\n",
        "tetrahedron_vertices = np.array([p1_coords, p2_coords, p3_coords, q_coords])\n",
        "\n",
        "# Define the edges of the tetrahedron (indices of vertices)\n",
        "tetrahedron_edges = [\n",
        "    (0, 1), (0, 2), (0, 3),  # Edges from P1 to P2, P3, Q?\n",
        "    (1, 2), (1, 3),          # Edges from P2 to P3, Q?\n",
        "    (2, 3)                   # Edge from P3 to Q?\n",
        "]\n",
        "\n",
        "# Create the lines for the tetrahedron edges\n",
        "lines = []\n",
        "for i, (start_index, end_index) in enumerate(tetrahedron_edges):\n",
        "    start_point = tetrahedron_vertices[start_index]\n",
        "    end_point = tetrahedron_vertices[end_index]\n",
        "    lines.append(\n",
        "        go.Scatter3d(\n",
        "            x=[start_point[0], end_point[0]],\n",
        "            y=[start_point[1], end_point[1]],\n",
        "            z=[start_point[2], end_point[2]],\n",
        "            mode='lines',\n",
        "            line=dict(color='red', width=4),  # Style the lines\n",
        "            name=f'Edge {i+1}'\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Create the 3D scatter plot and add the lines\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=reduced_embeddings_3d[:, 0],\n",
        "    y=reduced_embeddings_3d[:, 1],\n",
        "    z=reduced_embeddings_3d[:, 2],\n",
        "    mode='markers+text',\n",
        "    text=labels,  # Use first 2 characters of labels\n",
        "    textposition=\"middle right\",\n",
        "    marker=dict(size=8),\n",
        "    name='Data Points'\n",
        ")] + lines)  # Combine scatter and lines\n",
        "\n",
        "# Set the title and axis labels\n",
        "fig.update_layout(\n",
        "    title=\"3D PCA Visualization with Tetrahedron\",\n",
        "    scene=dict(\n",
        "        xaxis_title=\"PC 1\",\n",
        "        yaxis_title=\"PC 2\",\n",
        "        zaxis_title=\"PC 3\",\n",
        "    ),\n",
        "    margin=dict(l=0, r=0, b=0, t=0),\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "hEAM8I15WJ_K",
        "outputId": "f4d80bfe-91d8-4b11-fd66-26ab613e182f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3cc08523-2df3-4b70-9ee2-a562d87c213b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3cc08523-2df3-4b70-9ee2-a562d87c213b\")) {                    Plotly.newPlot(                        \"3cc08523-2df3-4b70-9ee2-a562d87c213b\",                        [{\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"Data Points\",\"text\":[\"Pa\",\"P1\",\"P2\",\"Pa\",\"Q?\",\"Ax\",\"Bx\",\"Cx\",\"Dv\"],\"textposition\":\"middle right\",\"x\":[-0.3440965,-0.21080051,-0.2572832,-0.34409657,0.9101867,-0.014139316,0.12878378,0.029401414,0.102044426],\"y\":[-0.25143966,-0.3544379,-0.048803065,-0.2514397,-0.35403314,0.38436484,0.23805006,0.3906051,0.24713343],\"z\":[0.047243502,-0.1984253,0.2176328,0.047243528,0.15259647,0.2861914,-0.4156562,0.28460795,-0.42143437],\"type\":\"scatter3d\"},{\"line\":{\"color\":\"red\",\"width\":4},\"mode\":\"lines\",\"name\":\"Edge 1\",\"x\":[-0.21080051362514496,-0.25728321075439453],\"y\":[-0.3544378876686096,-0.04880306497216225],\"z\":[-0.19842529296875,0.21763280034065247],\"type\":\"scatter3d\"},{\"line\":{\"color\":\"red\",\"width\":4},\"mode\":\"lines\",\"name\":\"Edge 2\",\"x\":[-0.21080051362514496,-0.3440965712070465],\"y\":[-0.3544378876686096,-0.2514396905899048],\"z\":[-0.19842529296875,0.04724352806806564],\"type\":\"scatter3d\"},{\"line\":{\"color\":\"red\",\"width\":4},\"mode\":\"lines\",\"name\":\"Edge 3\",\"x\":[-0.21080051362514496,0.9101867079734802],\"y\":[-0.3544378876686096,-0.35403314232826233],\"z\":[-0.19842529296875,0.15259647369384766],\"type\":\"scatter3d\"},{\"line\":{\"color\":\"red\",\"width\":4},\"mode\":\"lines\",\"name\":\"Edge 4\",\"x\":[-0.25728321075439453,-0.3440965712070465],\"y\":[-0.04880306497216225,-0.2514396905899048],\"z\":[0.21763280034065247,0.04724352806806564],\"type\":\"scatter3d\"},{\"line\":{\"color\":\"red\",\"width\":4},\"mode\":\"lines\",\"name\":\"Edge 5\",\"x\":[-0.25728321075439453,0.9101867079734802],\"y\":[-0.04880306497216225,-0.35403314232826233],\"z\":[0.21763280034065247,0.15259647369384766],\"type\":\"scatter3d\"},{\"line\":{\"color\":\"red\",\"width\":4},\"mode\":\"lines\",\"name\":\"Edge 6\",\"x\":[-0.3440965712070465,0.9101867079734802],\"y\":[-0.2514396905899048,-0.35403314232826233],\"z\":[0.04724352806806564,0.15259647369384766],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"l\":0,\"r\":0,\"b\":0,\"t\":0},\"title\":{\"text\":\"3D PCA Visualization with Tetrahedron\"},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"PC 1\"}},\"yaxis\":{\"title\":{\"text\":\"PC 2\"}},\"zaxis\":{\"title\":{\"text\":\"PC 3\"}}},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3cc08523-2df3-4b70-9ee2-a562d87c213b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 3D PCA from multiple angles static\n",
        "\n",
        "In case rotational view above isn't available at temp environment, use multi-angle to illustrate."
      ],
      "metadata": {
        "id": "iGJWUAOfxByM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA from multiple angles static views\n",
        "pca_3d = PCA(n_components=3)\n",
        "reduced_embeddings_3d = pca_3d.fit_transform(embeddings)\n",
        "\n",
        "#Create various angles for multiple 3-D rendering\n",
        "elevations = [30, 30, 0, -30]  # Angles of elevation\n",
        "azim_angles = [0, 45, 90, 135] # Azimuthal angles\n",
        "\n",
        "for i, (elev, azim) in enumerate(zip(elevations, azim_angles)):\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter(reduced_embeddings_3d[:, 0], reduced_embeddings_3d[:, 1], reduced_embeddings_3d[:, 2])\n",
        "    for j, txt in enumerate(sentences):\n",
        "        ax.text(reduced_embeddings_3d[j, 0], reduced_embeddings_3d[j, 1], reduced_embeddings_3d[j, 2], txt[:2])\n",
        "    ax.set_xlabel(\"PC 1\")\n",
        "    ax.set_ylabel(\"PC 2\")\n",
        "    ax.set_zlabel(\"PC 3\")\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "    plt.title(f\"3D Plot (Elev={elev}, Azim={azim})\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qzJJQ2qd59hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Using t-SNE for Dimensionality Reduction\n",
        "\n",
        "**t-SNE** = t-distributed stochastic neighbor embedding. Unlike **PCA**, **t-SNE** demonstrate the embeddings in non-linear more scattered fashion.\n"
      ],
      "metadata": {
        "id": "E2N5RVTwCs8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 2D t-SNE"
      ],
      "metadata": {
        "id": "ZKd0J7HaxlFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reduce to 2 dimensions using t-SNE with a lower perplexity\n",
        "tsne_2d = TSNE(n_components=2, random_state=42, n_iter=300, perplexity=min(5, len(sentences) - 1)) # Set perplexity <= 5 or n_samples - 1\n",
        "reduced_embeddings_tsne_2d = tsne_2d.fit_transform(embeddings)\n",
        "\n",
        "# Visualize the 2D embeddings (t-SNE)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(reduced_embeddings_tsne_2d[:, 0], reduced_embeddings_tsne_2d[:, 1])\n",
        "\n",
        "# Annotate each point with the corresponding sentence\n",
        "for i, txt in enumerate(sentences):\n",
        "    plt.annotate(txt[:2], (reduced_embeddings_tsne_2d[i, 0], reduced_embeddings_tsne_2d[i, 1]))\n",
        "\n",
        "plt.title(\"2D Visualization of Sentence Embeddings (t-SNE)\")\n",
        "plt.xlabel(\"t-SNE D1\")\n",
        "plt.ylabel(\"t-SNE D2\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8lgTh7bOEX6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.2 3D t-SNE static"
      ],
      "metadata": {
        "id": "NgbblG8Mxsy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Reduce to 3 dimensions using t-SNE with a lower perplexity\n",
        "tsne_3d = TSNE(n_components=3, random_state=42, n_iter=300, perplexity=min(5, len(sentences) - 1))\n",
        "reduced_embeddings_tsne_3d = tsne_3d.fit_transform(embeddings)\n",
        "\n",
        "# Visualize the 3D embeddings\n",
        "fig_3d = plt.figure(figsize=(4, 3))\n",
        "ax_3d = fig_3d.add_subplot(111, projection='3d')\n",
        "scatter_3d = ax_3d.scatter(reduced_embeddings_tsne_3d[:, 0], reduced_embeddings_tsne_3d[:, 1], reduced_embeddings_tsne_3d[:, 2])\n",
        "\n",
        "# Annotate each point with the first letter of the sentence\n",
        "for i, txt in enumerate(sentences):\n",
        "    ax_3d.text(reduced_embeddings_tsne_3d[i, 0], reduced_embeddings_tsne_3d[i, 1], reduced_embeddings_tsne_3d[i, 2], txt[:2])\n",
        "\n",
        "ax_3d.set_xlabel(\"t-SNE D1\")\n",
        "ax_3d.set_ylabel(\"t-SNE D2\")\n",
        "ax_3d.set_zlabel(\"t-SNE D3\")\n",
        "ax_3d.set_title(\"3D Visualization of Sentence Embeddings (t-SNE)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VoIIlz1E3e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.3 3D t-SNE rotational"
      ],
      "metadata": {
        "id": "UinugAfyxyO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Assuming you have your data in a variable called 'embeddings'\n",
        "# For example, let's create some dummy data for demonstration:\n",
        "embeddings = np.random.rand(9, 5)  # 9 samples, 5 dimensions\n",
        "sentences = [\n",
        "    \"Pa: Some fuel additives\",\n",
        "    \"P1: Some fuel additives\",\n",
        "    \"P2: In a 2015 study\",\n",
        "    \"P3: While bioaccumulation\",\n",
        "    \"Q?: Which finding\",\n",
        "    \"Ax) When D. polymorpha\",\n",
        "    \"Bv) The rate of CeO2-NPs\",\n",
        "    \"Cx) D.polymorpha has been\",\n",
        "    \"Dx) Compared with O. mykiss\"\n",
        "]\n",
        "labels = [s[:2] for s in sentences]  # Get first two letters.\n",
        "\n",
        "# Perform PCA to reduce to 3 dimensions\n",
        "pca_3d = PCA(n_components=3)\n",
        "reduced_embeddings_tsne_3d = pca_3d.fit_transform(embeddings)\n",
        "\n",
        "# Directly define the indices, assuming P1, P2, P3, Q? are at indices 1, 2, 3, and 4\n",
        "p1_index = 1\n",
        "p2_index = 2\n",
        "p3_index = 3\n",
        "q_index = 4\n",
        "\n",
        "# Extract the 3D coordinates of P1, P2, P3, and Q?\n",
        "p1_coords = reduced_embeddings_tsne_3d[p1_index]\n",
        "p2_coords = reduced_embeddings_tsne_3d[p2_index]\n",
        "p3_coords = reduced_embeddings_tsne_3d[p3_index]\n",
        "q_coords = reduced_embeddings_tsne_3d[q_index]\n",
        "\n",
        "# Define the vertices of the tetrahedron\n",
        "tetrahedron_vertices = np.array([p1_coords, p2_coords, p3_coords, q_coords])\n",
        "\n",
        "# Define the edges of the tetrahedron (indices of vertices)\n",
        "tetrahedron_edges = [\n",
        "    (0, 1), (0, 2), (0, 3),  # Edges from P1 to P2, P3, Q?\n",
        "    (1, 2), (1, 3),          # Edges from P2 to P3, Q?\n",
        "    (2, 3)                   # Edge from P3 to Q?\n",
        "]\n",
        "\n",
        "# Create the lines for the tetrahedron edges\n",
        "lines = []\n",
        "for i, (start_index, end_index) in enumerate(tetrahedron_edges):\n",
        "    start_point = tetrahedron_vertices[start_index]\n",
        "    end_point = tetrahedron_vertices[end_index]\n",
        "    lines.append(\n",
        "        go.Scatter3d(\n",
        "            x=[start_point[0], end_point[0]],\n",
        "            y=[start_point[1], end_point[1]],\n",
        "            z=[start_point[2], end_point[2]],\n",
        "            mode='lines',\n",
        "            line=dict(color='red', width=4),  # Style the lines\n",
        "            name=f'Edge {i+1}'\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Create the 3D scatter plot and add the lines\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=reduced_embeddings_tsne_3d[:, 0],\n",
        "    y=reduced_embeddings_tsne_3d[:, 1],\n",
        "    z=reduced_embeddings_tsne_3d[:, 2],\n",
        "    mode='markers+text',\n",
        "    text=labels,  # Use first 2 characters of labels\n",
        "    textposition=\"middle right\",\n",
        "    marker=dict(size=8),\n",
        "    name='Data Points'\n",
        ")] + lines)  # Combine scatter and lines\n",
        "\n",
        "# Set the title and axis labels\n",
        "fig.update_layout(\n",
        "    title=\"3D PCA Visualization with Tetrahedron\",\n",
        "    scene=dict(\n",
        "        xaxis_title=\"PC 1\",\n",
        "        yaxis_title=\"PC 2\",\n",
        "        zaxis_title=\"PC 3\",\n",
        "    ),\n",
        "    margin=dict(l=0, r=0, b=0, t=0),\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Q6Sj8TzBJLyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. How about 5-Vs?\n",
        "\n",
        "### 8.1 Initialized 5V (CL 1wk + DR 1wk)\n",
        "\n",
        "Below is a typical preception with inital training/ While erros exist across V2/V3/V4/V5, the student can vaguely see the correct answer Bv from the wrong choices Ax, Cx, and Dx.\n",
        "\n",
        "5Vs---Pa---P1---P2---P3---Q?---Ax---Bv---Cx---Dx---\n",
        "\n",
        "V1-----0-----1-----0------0-----1------0-----1-----0-----1---\n",
        "\n",
        "V2-----1-----0----0.5---1------0-----0----0.5----0-----0---\n",
        "\n",
        "V3-----1-----0----0.5---1-----1------1-----1-----1-----1---\n",
        "\n",
        "V4-----0-----1-----0-----0-----1------0-----1----0.5----1---\n",
        "\n",
        "V5-----0-----1-----0----0.5----0------0-----0-----0-----1---"
      ],
      "metadata": {
        "id": "1Bdv-muoBmlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Your data as a string (including header row)\n",
        "data_string = \"\"\"datapoint,V1,V2,V3,V4,V5\n",
        "Pa,0,1,1,0,0\n",
        "P1,0,0,0,1,1\n",
        "P2,0,0.5,0.5,0,0\n",
        "P3,0,1,1,0,0.5\n",
        "Q?,1,0,1,1,0\n",
        "Ax,0,0,1,0,0\n",
        "Bv,1,0.5,1,1,0\n",
        "Cx,0,0,1,0.5,0\n",
        "Dx,1,0,1,1,1\n",
        "\"\"\"\n",
        "\n",
        "# Load the data from the string into a Pandas DataFrame\n",
        "from io import StringIO\n",
        "df = pd.read_csv(StringIO(data_string))\n",
        "\n",
        "# Extract the data for PCA (exclude the 'datapoint' column)\n",
        "X = df.iloc[:, 1:].values  # Get values from columns V1 to V5\n",
        "\n",
        "# Extract the datapoint labels\n",
        "labels = df['datapoint'].tolist()\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=3)\n",
        "reduced_data = pca.fit_transform(X)\n",
        "\n",
        "# Get the indices of P1, P2, P3, and Q?\n",
        "p1_index = labels.index('P1')\n",
        "p2_index = labels.index('P2')\n",
        "p3_index = labels.index('P3')\n",
        "q_index = labels.index('Q?')\n",
        "\n",
        "# Extract the 3D coordinates of P1, P2, P3, and Q?\n",
        "p1_coords = reduced_data[p1_index]\n",
        "p2_coords = reduced_data[p2_index]\n",
        "p3_coords = reduced_data[p3_index]\n",
        "q_coords = reduced_data[q_index]\n",
        "\n",
        "# Define the vertices of the tetrahedron\n",
        "tetrahedron_vertices = np.array([p1_coords, p2_coords, p3_coords, q_coords])\n",
        "\n",
        "# Define the edges of the tetrahedron (indices of vertices)\n",
        "tetrahedron_edges = [\n",
        "    (0, 1), (0, 2), (0, 3),  # Edges from P1 to P2, P3, Q?\n",
        "    (1, 2), (1, 3),          # Edges from P2 to P3, Q?\n",
        "    (2, 3)                   # Edge from P3 to Q?\n",
        "]\n",
        "\n",
        "# Create the 3D scatter plot for all points\n",
        "scatter = go.Scatter3d(\n",
        "    x=reduced_data[:, 0],\n",
        "    y=reduced_data[:, 1],\n",
        "    z=reduced_data[:, 2],\n",
        "    mode='markers+text',\n",
        "    text=labels,\n",
        "    textposition=\"middle right\",\n",
        "    marker=dict(size=8),\n",
        "    name='Data Points'  # Add a name for the scatter plot\n",
        ")\n",
        "\n",
        "# Create the lines for the tetrahedron edges\n",
        "lines = []\n",
        "for i, (start_index, end_index) in enumerate(tetrahedron_edges):\n",
        "    start_point = tetrahedron_vertices[start_index]\n",
        "    end_point = tetrahedron_vertices[end_index]\n",
        "    lines.append(\n",
        "        go.Scatter3d(\n",
        "            x=[start_point[0], end_point[0]],\n",
        "            y=[start_point[1], end_point[1]],\n",
        "            z=[start_point[2], end_point[2]],\n",
        "            mode='lines',\n",
        "            line=dict(color='red', width=4),  # Style the lines\n",
        "            name=f'Edge {i+1}' # Add a name for each line.\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Combine scatter and lines\n",
        "data = [scatter] + lines\n",
        "\n",
        "# Set the title and axis labels\n",
        "layout = go.Layout(\n",
        "    title=\"3D PCA of Data with Tetrahedron\",\n",
        "    scene=dict(\n",
        "        xaxis_title=\"PC 1\",\n",
        "        yaxis_title=\"PC 2\",\n",
        "        zaxis_title=\"PC 3\",\n",
        "    ),\n",
        "    margin=dict(l=0, r=0, b=0, t=0),\n",
        "    showlegend=True #show legend\n",
        ")\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "# Show the plot (this will display an interactive plot in Colab)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "5e3crrvNJ33O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2 Well-Trained 5Vs: CL 1wk + DP/BT>=1month\n",
        "\n",
        "Below is a typical preception with 1+month training. Correct answer falls directly into the prompt/question subspace.\n",
        "\n",
        "5Vs---Pa---P1---P2---P3---Q?---Ax---Bv---Cx---Dx---\n",
        "\n",
        "V1-----0-----1-----0------0-----1------0-----1-----0-----1---\n",
        "\n",
        "V2-----1-----0-----1-----1------0------0-----0-----0-----0---\n",
        "\n",
        "V3-----1-----0-----1------1-----1------1-----1-----1-----1---\n",
        "\n",
        "V4-----0-----1-----0-----0-----1------0------1-----1-----1---\n",
        "\n",
        "V5-----0-----1-----0-----1-----0------0------0-----0-----1---"
      ],
      "metadata": {
        "id": "GiE1M_gtFaj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Your data as a string (including header row)\n",
        "data_string = \"\"\"datapoint,V1,V2,V3,V4,V5\n",
        "Pa,0,1,1,0,1\n",
        "P1,1,0,0,1,1\n",
        "P2,0,1,1,0,0\n",
        "P3,0,1,1,0,1\n",
        "Q?,1,0,1,1,0\n",
        "Ax,0,0,1,0,0\n",
        "Bv,1,0,1,1,0\n",
        "Cx,0,0,1,1,0\n",
        "Dx,1,0,1,1,1\n",
        "\"\"\"\n",
        "\n",
        "# Load the data from the string into a Pandas DataFrame\n",
        "from io import StringIO\n",
        "df = pd.read_csv(StringIO(data_string))\n",
        "\n",
        "# Extract the data for PCA (exclude the 'datapoint' column)\n",
        "X = df.iloc[:, 1:].values  # Get values from columns V1 to V5\n",
        "\n",
        "# Extract the datapoint labels\n",
        "labels = df['datapoint'].tolist()\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=3)\n",
        "reduced_data = pca.fit_transform(X)\n",
        "\n",
        "# Get the indices of P1, P2, P3, and Q?\n",
        "p1_index = labels.index('P1')\n",
        "p2_index = labels.index('P2')\n",
        "p3_index = labels.index('P3')\n",
        "q_index = labels.index('Q?')\n",
        "\n",
        "# Extract the 3D coordinates of P1, P2, P3, and Q?\n",
        "p1_coords = reduced_data[p1_index]\n",
        "p2_coords = reduced_data[p2_index]\n",
        "p3_coords = reduced_data[p3_index]\n",
        "q_coords = reduced_data[q_index]\n",
        "\n",
        "# Define the vertices of the tetrahedron\n",
        "tetrahedron_vertices = np.array([p1_coords, p2_coords, p3_coords, q_coords])\n",
        "\n",
        "# Define the edges of the tetrahedron (indices of vertices)\n",
        "tetrahedron_edges = [\n",
        "    (0, 1), (0, 2), (0, 3),  # Edges from P1 to P2, P3, Q?\n",
        "    (1, 2), (1, 3),          # Edges from P2 to P3, Q?\n",
        "    (2, 3)                   # Edge from P3 to Q?\n",
        "]\n",
        "\n",
        "# Create the 3D scatter plot for all points\n",
        "scatter = go.Scatter3d(\n",
        "    x=reduced_data[:, 0],\n",
        "    y=reduced_data[:, 1],\n",
        "    z=reduced_data[:, 2],\n",
        "    mode='markers+text',\n",
        "    text=labels,\n",
        "    textposition=\"middle right\",\n",
        "    marker=dict(size=8),\n",
        "    name='Data Points'  # Add a name for the scatter plot\n",
        ")\n",
        "\n",
        "# Create the lines for the tetrahedron edges\n",
        "lines = []\n",
        "for i, (start_index, end_index) in enumerate(tetrahedron_edges):\n",
        "    start_point = tetrahedron_vertices[start_index]\n",
        "    end_point = tetrahedron_vertices[end_index]\n",
        "    lines.append(\n",
        "        go.Scatter3d(\n",
        "            x=[start_point[0], end_point[0]],\n",
        "            y=[start_point[1], end_point[1]],\n",
        "            z=[start_point[2], end_point[2]],\n",
        "            mode='lines',\n",
        "            line=dict(color='red', width=4),  # Style the lines\n",
        "            name=f'Edge {i+1}' # Add a name for each line.\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Combine scatter and lines\n",
        "data = [scatter] + lines\n",
        "\n",
        "# Set the title and axis labels\n",
        "layout = go.Layout(\n",
        "    title=\"3D PCA of Data with Tetrahedron\",\n",
        "    scene=dict(\n",
        "        xaxis_title=\"PC 1\",\n",
        "        yaxis_title=\"PC 2\",\n",
        "        zaxis_title=\"PC 3\",\n",
        "    ),\n",
        "    margin=dict(l=0, r=0, b=0, t=0),\n",
        "    showlegend=True #show legend\n",
        ")\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "# Show the plot (this will display an interactive plot in Colab)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "ampbw-BTFY7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "LIT in Notebooks",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}